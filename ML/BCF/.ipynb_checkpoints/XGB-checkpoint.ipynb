{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, SelectFromModel\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_curve, auc, mean_squared_error, \\\n",
    "    r2_score, mean_absolute_error,cohen_kappa_score,accuracy_score,f1_score,matthews_corrcoef,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import multiprocessing\n",
    "start = time.time()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def standardize(col):\n",
    "    return (col - np.mean(col)) / np.std(col)\n",
    "\n",
    "# the metrics for classification\n",
    "def statistical(y_true, y_pred, y_pro):\n",
    "    c_mat = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = list(c_mat.flatten())\n",
    "    se = tp / (tp + fn)\n",
    "    sp = tn / (tn + fp)\n",
    "    auc_prc = auc(precision_recall_curve(y_true, y_pro, pos_label=1)[1],\n",
    "                  precision_recall_curve(y_true, y_pro, pos_label=1)[0])\n",
    "    acc = (tp + tn) / (tn + fp + fn + tp)\n",
    "#     acc_skl = accuracy_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pro)\n",
    "    recall = se\n",
    "#     recall_skl = recall_score(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "#     precision_skl = precision_score(y_true, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) # F1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     f1_skl = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true,y_pred)\n",
    "    mcc = (tp * tn - fp * fn) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn) + 1e-8)\n",
    "#     mcc_skl = matthews_corrcoef(y_true,y_pred)\n",
    "    return tn,fp,fn,tp,se,sp,auc_prc,acc,auc_roc,recall,precision,f1,kappa,mcc\n",
    "\n",
    "def all_one_zeros(data):\n",
    "    if (len(np.unique(data)) == 2):\n",
    "        flag = False\n",
    "    else:\n",
    "        flag = True\n",
    "    return flag\n",
    "\n",
    "\n",
    "feature_selection = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName= 'xgb'\n",
    "tasks = 'logBCF'\n",
    "data_file_1 = './data/BCF1859/BCF1859-SEED'\n",
    "data_file_2 = '-ECFP-group.csv'\n",
    "file_name = data_file_1+'0'+data_file_2\n",
    "dataset_label = 'BCF1859_ECFP'\n",
    "hyper_file_name = './model/' + dataset_label + '_'+modelName+'_hyperopt_info.csv'\n",
    "muti_tasks = ['logBCF']\n",
    "ecfp = True\n",
    "data_preprocessing = True\n",
    "task_type = 'reg'  # 'reg' or 'cla'\n",
    "OPT_ITERS = 50\n",
    "repetitions = 10\n",
    "patience = 50\n",
    "num_pools = 10\n",
    "GPUNum = 0\n",
    "\n",
    "# preset the hyper_parameters_space \n",
    "space_ = {'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "          'gamma': hp.uniform('gamma', 0, 0.2),\n",
    "          'min_child_weight': hp.choice('min_child_weight', range(1, 4)),\n",
    "          'subsample': hp.uniform('subsample', 0.2, 1.0),\n",
    "          'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "          'max_depth': hp.choice('max_depth', range(1, 11)),\n",
    "          'n_estimators': hp.choice('n_estimators', range(10,300,1)),\n",
    "          'reg_alpha': hp.loguniform('reg_alpha', 1e-10, 10.0),\n",
    "          'reg_lambda': hp.loguniform('reg_lambda', 1e-10, 10.0)\n",
    "         }\n",
    "          \n",
    "min_child_weight_ls = range(1, 4)\n",
    "max_depth_ls = range(1, 11)\n",
    "n_estimators_ls = range(10,300,1)\n",
    "\n",
    "dataset = pd.read_csv(file_name)\n",
    "pd_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_runing(subtask):\n",
    "\n",
    "    sub_dataset = dataset.drop(columns='SMILES')\n",
    "\n",
    "    if data_preprocessing:\n",
    "        # detect the na in the subtask (y cloumn)\n",
    "        rm_index = sub_dataset[subtask][sub_dataset[subtask].isnull()].index\n",
    "        sub_dataset.drop(index=rm_index, inplace=True)\n",
    "\n",
    "        # remove the features with na\n",
    "        sub_dataset = sub_dataset.dropna(axis=1)\n",
    "\n",
    "        # *******************\n",
    "        # demension reduction\n",
    "        # *******************\n",
    "        # Removing features with low variance\n",
    "        # threshold = 0.05\n",
    "        data_fea_var = sub_dataset.iloc[:, 2:].var()\n",
    "        del_fea1 = list(data_fea_var[data_fea_var <= 0.05].index)\n",
    "        sub_dataset.drop(columns=del_fea1, inplace=True)\n",
    "        # pair correlations\n",
    "        # threshold = 0.95\n",
    "        data_fea_corr = sub_dataset.iloc[:, 2:].corr()\n",
    "        del_fea2_col = []\n",
    "        del_fea2_ind = []\n",
    "        length = data_fea_corr.shape[1]\n",
    "        for i in range(length):\n",
    "            for j in range(i + 1, length):\n",
    "                if abs(data_fea_corr.iloc[i, j]) >= 0.95:\n",
    "                    del_fea2_col.append(data_fea_corr.columns[i])\n",
    "                    del_fea2_ind.append(data_fea_corr.index[j])\n",
    "        sub_dataset.drop(columns=del_fea2_ind, inplace=True)\n",
    "\n",
    "    # standardize the features\n",
    "    cols_ = list(sub_dataset.columns)[2:]\n",
    "    \n",
    "    if not ecfp :\n",
    "        sub_dataset[cols_] = sub_dataset[cols_].apply(standardize, axis=0)\n",
    "\n",
    "    # get the attentivefp data splits\n",
    "    data_tr = sub_dataset[sub_dataset['group'] == 'train']\n",
    "    data_va = sub_dataset[sub_dataset['group'] == 'valid']\n",
    "    data_te = sub_dataset[sub_dataset['group'] == 'test']\n",
    "\n",
    "    # prepare data for training\n",
    "    # training set\n",
    "    data_tr_y = data_tr[subtask].values.reshape(-1, 1)\n",
    "    data_tr_x = np.array(data_tr.iloc[:, 2:].values)\n",
    "\n",
    "    # validation set\n",
    "    data_va_y = data_va[subtask].values.reshape(-1, 1)\n",
    "    data_va_x = np.array(data_va.iloc[:, 2:].values)\n",
    "\n",
    "    # test set\n",
    "    data_te_y = data_te[subtask].values.reshape(-1, 1)\n",
    "    data_te_x = np.array(data_te.iloc[:, 2:].values)\n",
    "\n",
    "    if feature_selection:\n",
    "        # univariate feature selection\n",
    "        trans1 = SelectPercentile(f_classif, percentile=80)\n",
    "        trans1.fit(data_tr_x, data_tr_y)\n",
    "        data_tr_x = trans1.transform(data_tr_x)\n",
    "        data_va_x = trans1.transform(data_va_x)\n",
    "        data_te_x = trans1.transform(data_te_x)\n",
    "\n",
    "        # select from model\n",
    "        clf = XGBClassifier(n_jobs=12, random_state=1)\n",
    "        clf = clf.fit(data_tr_x, data_tr_y)\n",
    "        trans2 = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "        data_tr_x = trans2.transform(data_tr_x)\n",
    "        data_va_x = trans2.transform(data_va_x)\n",
    "        data_te_x = trans2.transform(data_te_x)\n",
    "\n",
    "    num_fea = data_tr_x.shape[1]\n",
    "    pos_weight = (len(sub_dataset) - sum(sub_dataset[subtask])) / sum(sub_dataset[subtask])\n",
    "    print('the num of retained features for the ' + dataset_label + ' ' + subtask + ' is:', num_fea)\n",
    "\n",
    "    def hyper_opt(args):\n",
    "\n",
    "        model = XGBClassifier(**args, n_jobs=6, random_state=1, \n",
    "                              seed=1\n",
    "                                 ) if task_type == 'cla' else XGBRegressor(**args, n_jobs=6,\n",
    "                                                                                                   random_state=1,\n",
    "                                                                                                   seed=1)\n",
    "\n",
    "        model.fit(data_tr_x, data_tr_y, eval_metric='auc' if task_type == 'cla' else 'rmse',\n",
    "                  eval_set=[(data_va_x, data_va_y)],\n",
    "                  early_stopping_rounds=patience, verbose=False)\n",
    "        val_preds = model.predict_proba(data_va_x, ntree_limit=model.best_ntree_limit) if task_type == 'cla' else \\\n",
    "            model.predict(data_va_x, ntree_limit=model.best_ntree_limit)\n",
    "        loss = 1 - roc_auc_score(data_va_y, val_preds[:, 1]) if task_type == 'cla' else np.sqrt(\n",
    "            mean_squared_error(data_va_y, val_preds))\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    # start hyper-parameters optimization\n",
    "    trials = Trials()\n",
    "    best_results = fmin(hyper_opt, space_, algo=tpe.suggest, max_evals=OPT_ITERS, trials=trials, show_progressbar=True)\n",
    "    print('the best hyper-parameters for ' + dataset_label + ' ' + subtask + ' are:  ', best_results)\n",
    "    best_model = XGBClassifier(n_estimators=n_estimators_ls[best_results['n_estimators']],\n",
    "                               max_depth=max_depth_ls[best_results['max_depth']],\n",
    "                               min_child_weight=min_child_weight_ls[best_results['min_child_weight']],\n",
    "                               learning_rate=best_results['learning_rate'],\n",
    "                               gamma=best_results['gamma'],\n",
    "                               subsample=best_results['subsample'],\n",
    "                               colsample_bytree=best_results['colsample_bytree'],\n",
    "                               reg_alpha=best_results['reg_alpha'],\n",
    "                               reg_lambda=best_results['reg_lambda'],\n",
    "                               n_jobs=6, random_state=1,\n",
    "                               seed=1) \\\n",
    "        if task_type == 'cla' else XGBRegressor(\n",
    "        n_estimators=n_estimators_ls[best_results['n_estimators']],\n",
    "        max_depth=max_depth_ls[best_results['max_depth']],\n",
    "        min_child_weight=min_child_weight_ls[best_results['min_child_weight']],\n",
    "        learning_rate=best_results['learning_rate'],\n",
    "        gamma=best_results['gamma'],\n",
    "        subsample=best_results['subsample'],\n",
    "        colsample_bytree=best_results['colsample_bytree'],\n",
    "        reg_alpha=best_results['reg_alpha'],\n",
    "        reg_lambda=best_results['reg_lambda'],        \n",
    "        n_jobs=6, random_state=1, seed=1)\n",
    "\n",
    "    best_model.fit(data_tr_x, data_tr_y, eval_metric='auc' if task_type == 'cla' else 'rmse',\n",
    "                   eval_set=[(data_va_x, data_va_y)],\n",
    "                   early_stopping_rounds=patience, verbose=False)\n",
    "    num_of_compounds = len(sub_dataset)\n",
    "\n",
    "    if task_type == 'cla':\n",
    "        # training set\n",
    "        tr_pred = best_model.predict_proba(data_tr_x, ntree_limit=best_model.best_ntree_limit)\n",
    "        tr_results = [dataset_label, subtask, 'tr', num_fea, num_of_compounds, data_tr_y[data_tr_y == 1].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0] / data_tr_y[data_tr_y == 1].shape[0],\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_child_weight_ls[best_results['min_child_weight']],\n",
    "                      best_results['learning_rate'], best_results['gamma'], best_results['subsample'],\n",
    "                      best_results['colsample_bytree'],\n",
    "                      best_results['reg_alpha'],best_results['reg_lambda']]\n",
    "        tr_results.extend(statistical(data_tr_y, np.argmax(tr_pred, axis=1), tr_pred[:, 1]))\n",
    "\n",
    "        # validation set\n",
    "        va_pred = best_model.predict_proba(data_va_x, ntree_limit=best_model.best_ntree_limit)\n",
    "        va_results = [dataset_label, subtask, 'va', num_fea, num_of_compounds, data_va_y[data_va_y == 1].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0] / data_va_y[data_va_y == 1].shape[0],\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_child_weight_ls[best_results['min_child_weight']],\n",
    "                      best_results['learning_rate'], best_results['gamma'], best_results['subsample'],\n",
    "                      best_results['colsample_bytree'],\n",
    "                      best_results['reg_alpha'],best_results['reg_lambda']]\n",
    "        va_results.extend(statistical(data_va_y, np.argmax(va_pred, axis=1), va_pred[:, 1]))\n",
    "\n",
    "        # test set\n",
    "        te_pred = best_model.predict_proba(data_te_x, ntree_limit=best_model.best_ntree_limit)\n",
    "        te_results = [dataset_label, subtask, 'te', num_fea, num_of_compounds, data_te_y[data_te_y == 1].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0] / data_te_y[data_te_y == 1].shape[0],\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_child_weight_ls[best_results['min_child_weight']],\n",
    "                      best_results['learning_rate'], best_results['gamma'], best_results['subsample'],\n",
    "                      best_results['colsample_bytree'],\n",
    "                      best_results['reg_alpha'],best_results['reg_lambda']]\n",
    "        te_results.extend(statistical(data_te_y, np.argmax(te_pred, axis=1), te_pred[:, 1]))\n",
    "    else:\n",
    "        # training set\n",
    "        tr_pred = best_model.predict(data_tr_x, ntree_limit=best_model.best_ntree_limit)\n",
    "        tr_results = [dataset_label, subtask, 'tr', num_fea, num_of_compounds,\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_child_weight_ls[best_results['min_child_weight']],\n",
    "                      best_results['learning_rate'], best_results['gamma'], best_results['subsample'],\n",
    "                      best_results['colsample_bytree'],\n",
    "                      best_results['reg_alpha'],best_results['reg_lambda'],\n",
    "                      np.sqrt(mean_squared_error(data_tr_y, tr_pred)), r2_score(data_tr_y, tr_pred),\n",
    "                      mean_absolute_error(data_tr_y, tr_pred)]\n",
    "\n",
    "        # validation set\n",
    "        va_pred = best_model.predict(data_va_x, ntree_limit=best_model.best_ntree_limit)\n",
    "        va_results = [dataset_label, subtask, 'va', num_fea, num_of_compounds,\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_child_weight_ls[best_results['min_child_weight']],\n",
    "                      best_results['learning_rate'], best_results['gamma'], best_results['subsample'],\n",
    "                      best_results['colsample_bytree'],\n",
    "                      best_results['reg_alpha'],best_results['reg_lambda'],\n",
    "                      np.sqrt(mean_squared_error(data_va_y, va_pred)), r2_score(data_va_y, va_pred),\n",
    "                      mean_absolute_error(data_va_y, va_pred)]\n",
    "\n",
    "        # test set\n",
    "        te_pred = best_model.predict(data_te_x, ntree_limit=best_model.best_ntree_limit)\n",
    "        te_results = [dataset_label, subtask, 'te', num_fea, num_of_compounds,\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_child_weight_ls[best_results['min_child_weight']],\n",
    "                      best_results['learning_rate'], best_results['gamma'], best_results['subsample'],\n",
    "                      best_results['colsample_bytree'],\n",
    "                      best_results['reg_alpha'],best_results['reg_lambda'],\n",
    "                      np.sqrt(mean_squared_error(data_te_y, te_pred)), r2_score(data_te_y, te_pred),\n",
    "                      mean_absolute_error(data_te_y, te_pred)]\n",
    "    return tr_results, va_results, te_results\n",
    "\n",
    "pool = multiprocessing.Pool(num_pools)\n",
    "res = pool.starmap(hyper_runing, zip(muti_tasks))\n",
    "pool.close()\n",
    "pool.join()\n",
    "for item in res:\n",
    "    for i in range(3):\n",
    "        pd_res.append(item[i])\n",
    "if task_type == 'cla':\n",
    "    best_hyper = pd.DataFrame(pd_res, columns=['dataset', 'subtask', 'set',\n",
    "                                               'num_of_retained_feature',\n",
    "                                               'num_of_compounds', 'postives',\n",
    "                                               'negtives', 'negtives/postives',\n",
    "                                               'n_estimators', 'max_depth', 'min_child_weight',\n",
    "                                               'learning_rate', 'gamma', 'subsample', 'colsample_bytree','reg_alpha','reg_lambda',\n",
    "                                               'tn', 'fp', 'fn', 'tp', 'se', 'sp',\n",
    "                                               'auc_prc', 'acc', 'auc_roc','recall','precision','f1','kappa','mcc'])\n",
    "else:\n",
    "    best_hyper = pd.DataFrame(pd_res, columns=['dataset', 'subtask', 'set',\n",
    "                                               'num_of_retained_feature',\n",
    "                                               'num_of_compounds', 'n_estimators', 'max_depth', 'min_child_weight',\n",
    "                                               'learning_rate', 'gamma', 'subsample', 'colsample_bytree','reg_alpha','reg_lambda',\n",
    "                                               'rmse', 'r2', 'mae'])\n",
    "best_hyper.to_csv( hyper_file_name, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_type == 'cla':\n",
    "    print('train', best_hyper[best_hyper['set'] == 'tr']['auc_roc'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'tr']['auc_prc'].mean())\n",
    "    print('valid', best_hyper[best_hyper['set'] == 'va']['auc_roc'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'va']['auc_prc'].mean())\n",
    "    print('test', best_hyper[best_hyper['set'] == 'te']['auc_roc'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'te']['auc_prc'].mean())\n",
    "else:\n",
    "    print('train', best_hyper[best_hyper['set'] == 'tr']['rmse'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'tr']['r2'].mean(), best_hyper[best_hyper['set'] == 'tr']['mae'].mean())\n",
    "    print('valid', best_hyper[best_hyper['set'] == 'va']['rmse'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'va']['r2'].mean(), best_hyper[best_hyper['set'] == 'va']['mae'].mean())\n",
    "    print('test', best_hyper[best_hyper['set'] == 'te']['rmse'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'te']['r2'].mean(), best_hyper[best_hyper['set'] == 'te']['mae'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_model_runing(data_tr,data_va,data_te,best_hyper,split):\n",
    "    \n",
    "    # prepare data for training\n",
    "    # training set\n",
    "    data_tr_y = data_tr[subtask].values.reshape(-1, 1)\n",
    "    data_tr_x = np.array(data_tr.iloc[:, 2:].values)\n",
    "    #data_tr.to_csv('./data/ECFP_xgbtrain_' + str(split) + '.csv')\n",
    "    # validation set\n",
    "    data_va_y = data_va[subtask].values.reshape(-1, 1)\n",
    "    data_va_x = np.array(data_va.iloc[:, 2:].values)\n",
    "    #data_va.to_csv('./data/rdkit_xgbval_' + str(split) + '.csv')\n",
    "    # test set\n",
    "    data_te_y = data_te[subtask].values.reshape(-1, 1)\n",
    "    data_te_x = np.array(data_te.iloc[:, 2:].values)\n",
    "   # data_te.to_csv('./data/rdkit_xgbte_' + str(split) + '.csv')\n",
    "    if feature_selection:\n",
    "        # univariate feature selection\n",
    "        trans1 = SelectPercentile(f_classif, percentile=80)\n",
    "        trans1.fit(data_tr_x, data_tr_y)\n",
    "        data_tr_x = trans1.transform(data_tr_x)\n",
    "        data_va_x = trans1.transform(data_va_x)\n",
    "        data_te_x = trans1.transform(data_te_x)\n",
    "\n",
    "        # select from model\n",
    "        clf = XGBClassifier(n_jobs=6, random_state=1)\n",
    "        clf = clf.fit(data_tr_x, data_tr_y)\n",
    "        trans2 = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "        data_tr_x = trans2.transform(data_tr_x)\n",
    "        data_va_x = trans2.transform(data_va_x)\n",
    "        data_te_x = trans2.transform(data_te_x)\n",
    "\n",
    "    num_fea = data_tr_x.shape[1]\n",
    "    pos_weight = (len(sub_dataset) - sum(sub_dataset[subtask])) / sum(sub_dataset[subtask])\n",
    "    model = XGBClassifier(n_estimators=best_hyper[best_hyper.subtask == subtask].iloc[0,]['n_estimators'],\n",
    "                          max_depth=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_depth'],\n",
    "                          min_child_weight=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_child_weight'],\n",
    "                          learning_rate=best_hyper[best_hyper.subtask == subtask].iloc[0,]['learning_rate'],\n",
    "                          gamma=best_hyper[best_hyper.subtask == subtask].iloc[0,]['gamma'],\n",
    "                          subsample=best_hyper[best_hyper.subtask == subtask].iloc[0,]['subsample'],\n",
    "                          colsample_bytree=best_hyper[best_hyper.subtask == subtask].iloc[0,]['colsample_bytree'],\n",
    "                          reg_alpha=best_hyper[best_hyper.subtask == subtask].iloc[0,]['reg_alpha'],\n",
    "                          reg_lambda=best_hyper[best_hyper.subtask == subtask].iloc[0,]['reg_lambda'],\n",
    "                          n_jobs=6, random_state=1\n",
    "                          , seed=1\n",
    "                          ) \\\n",
    "        if task_type == 'cla' else XGBRegressor(\n",
    "        n_estimators=best_hyper[best_hyper.subtask == subtask].iloc[0,]['n_estimators'],\n",
    "        max_depth=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_depth'],\n",
    "        min_child_weight=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_child_weight'],\n",
    "        learning_rate=best_hyper[best_hyper.subtask == subtask].iloc[0,]['learning_rate'],\n",
    "        gamma=best_hyper[best_hyper.subtask == subtask].iloc[0,]['gamma'],\n",
    "        subsample=best_hyper[best_hyper.subtask == subtask].iloc[0,]['subsample'],\n",
    "        colsample_bytree=best_hyper[best_hyper.subtask == subtask].iloc[0,]['colsample_bytree'],\n",
    "        reg_alpha=best_hyper[best_hyper.subtask == subtask].iloc[0,]['reg_alpha'],\n",
    "        reg_lambda=best_hyper[best_hyper.subtask == subtask].iloc[0,]['reg_lambda'],\n",
    "        n_jobs=6, random_state=1, seed=1)\n",
    "\n",
    "    model.fit(data_tr_x, data_tr_y, eval_metric='auc' if task_type == 'cla' else 'rmse',\n",
    "              eval_set=[(data_va_x, data_va_y)],\n",
    "              early_stopping_rounds=patience, verbose=False)\n",
    "    num_of_compounds = sub_dataset.shape[0]\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    pickle.dump(model, open(\"./model/\"+modelName+\"_\"+str(split)+\"_\"+dataset_label+\".pkl\", \"wb\"))\n",
    "    \n",
    "    if task_type == 'cla':\n",
    "        # training set\n",
    "        tr_pred = model.predict_proba(data_tr_x, ntree_limit=model.best_ntree_limit)\n",
    "        tr_results = [split, dataset_label, subtask, 'tr', num_fea, num_of_compounds,\n",
    "                      data_tr_y[data_tr_y == 1].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0] / data_tr_y[data_tr_y == 1].shape[0]]\n",
    "        tr_results.extend(statistical(data_tr_y, np.argmax(tr_pred, axis=1), tr_pred[:, 1]))\n",
    "\n",
    "        # validation set\n",
    "        va_pred = model.predict_proba(data_va_x, ntree_limit=model.best_ntree_limit)\n",
    "        va_results = [split, dataset_label, subtask, 'va', num_fea, num_of_compounds,\n",
    "                      data_va_y[data_va_y == 1].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0] / data_va_y[data_va_y == 1].shape[0]]\n",
    "        va_results.extend(statistical(data_va_y, np.argmax(va_pred, axis=1), va_pred[:, 1]))\n",
    "\n",
    "        # test set\n",
    "        te_pred = model.predict_proba(data_te_x, ntree_limit=model.best_ntree_limit)\n",
    "        te_results = [split, dataset_label, subtask, 'te', num_fea, num_of_compounds,\n",
    "                      data_te_y[data_te_y == 1].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0] / data_te_y[data_te_y == 1].shape[0]]\n",
    "        te_results.extend(statistical(data_te_y, np.argmax(te_pred, axis=1), te_pred[:, 1]))\n",
    "    else:\n",
    "        # training set\n",
    "        tr_pred = model.predict(data_tr_x, ntree_limit=model.best_ntree_limit)\n",
    "        tr_results = [split, dataset_label, subtask, 'tr', num_fea, num_of_compounds,\n",
    "                      np.sqrt(mean_squared_error(data_tr_y, tr_pred)), r2_score(data_tr_y, tr_pred),\n",
    "                      mean_absolute_error(data_tr_y, tr_pred)]\n",
    "\n",
    "        # validation set\n",
    "        va_pred = model.predict(data_va_x, ntree_limit=model.best_ntree_limit)\n",
    "        va_results = [split, dataset_label, subtask, 'va', num_fea, num_of_compounds,\n",
    "                      np.sqrt(mean_squared_error(data_va_y, va_pred)), r2_score(data_va_y, va_pred),\n",
    "                      mean_absolute_error(data_va_y, va_pred)]\n",
    "\n",
    "        # test set\n",
    "        te_pred = model.predict(data_te_x, ntree_limit=model.best_ntree_limit)\n",
    "        te_results = [split, dataset_label, subtask, 'te', num_fea, num_of_compounds,\n",
    "                      np.sqrt(mean_squared_error(data_te_y, te_pred)), r2_score(data_te_y, te_pred),\n",
    "                      mean_absolute_error(data_te_y, te_pred)]\n",
    "        \n",
    "    return tr_results, va_results, te_results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_res = []\n",
    "for split in range(1, 11):\n",
    "    # 10 repetitions based on thr best hypers\n",
    "    file_name = data_file_1+str(split)+data_file_2\n",
    "    best_hyper = pd.read_csv(hyper_file_name)\n",
    "    sub_dataset = pd.read_csv(file_name)\n",
    "    subtask = tasks\n",
    "\n",
    "    if data_preprocessing:\n",
    "        # detect the na in the subtask (y cloumn)\n",
    "        rm_index = sub_dataset[subtask][sub_dataset[subtask].isnull()].index\n",
    "        sub_dataset.drop(index=rm_index, inplace=True)\n",
    "\n",
    "        # remove the features with na\n",
    "        sub_dataset = sub_dataset.dropna(axis=1)\n",
    "        # *******************\n",
    "        # demension reduction\n",
    "        # *******************\n",
    "        # Removing features with low variance\n",
    "        # threshold = 0.05\n",
    "        data_fea_var = sub_dataset.iloc[:, 3:].var()\n",
    "        del_fea1 = list(data_fea_var[data_fea_var <= 0.05].index)\n",
    "        sub_dataset.drop(columns=del_fea1, inplace=True)\n",
    "\n",
    "        # pair correlations\n",
    "        # threshold = 0.95\n",
    "        data_fea_corr = sub_dataset.iloc[:, 3:].corr()\n",
    "        del_fea2_col = []\n",
    "        del_fea2_ind = []\n",
    "        length = data_fea_corr.shape[1]\n",
    "        for i in range(length):\n",
    "            for j in range(i + 1, length):\n",
    "                if abs(data_fea_corr.iloc[i, j]) >= 0.95:\n",
    "                    del_fea2_col.append(data_fea_corr.columns[i])\n",
    "                    del_fea2_ind.append(data_fea_corr.index[j])\n",
    "        sub_dataset.drop(columns=del_fea2_ind, inplace=True)\n",
    "\n",
    "    # standardize the features\n",
    "    cols_ = list(sub_dataset.columns)[3:]\n",
    "    if not ecfp :\n",
    "        sub_dataset[cols_] = sub_dataset[cols_].apply(standardize, axis=0)\n",
    "\n",
    "    # get the data splits\n",
    "    data_tr = sub_dataset[sub_dataset['group'] == 'train'].drop(columns='SMILES')\n",
    "    data_va = sub_dataset[sub_dataset['group'] == 'valid'].drop(columns='SMILES')\n",
    "    data_te = sub_dataset[sub_dataset['group'] == 'test'].drop(columns='SMILES')\n",
    "\n",
    "    res = sp_model_runing(data_tr,data_va,data_te,best_hyper,split)\n",
    "    for i in range(3):\n",
    "        pd_res.append(res[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_fea_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_fea_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cols_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if task_type == 'cla':\n",
    "    stat_res = pd.DataFrame(pd_res, columns=['split', 'dataset', 'subtask', 'set',\n",
    "                                             'num_of_retained_feature',\n",
    "                                             'num_of_compounds', 'postives',\n",
    "                                             'negtives', 'negtives/postives',\n",
    "                                             'tn', 'fp', 'fn', 'tp', 'se', 'sp',\n",
    "                                             'auc_prc', 'acc', 'auc_roc','recall','precision','f1','kappa','mcc'])\n",
    "else:\n",
    "    stat_res = pd.DataFrame(pd_res, columns=['split', 'dataset', 'subtask', 'set',\n",
    "                                             'num_of_retained_feature',\n",
    "                                             'num_of_compounds', 'rmse', 'r2', 'mae'])\n",
    "stat_res.to_csv('./model/' + dataset_label + '_'+modelName+'_statistical_results_split.csv', index=0)\n",
    "stat_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'data_label': dataset_label, 'metric': 'auc_roc' if task_type == 'cla' else 'rmse', 'model': modelName}\n",
    "print('{}_{}: the mean {} for the training set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                 'r2', np.mean(\n",
    "        stat_res[stat_res['set'] == 'tr']['r2']), np.std(\n",
    "        stat_res[stat_res['set'] == 'tr']['r2'])))\n",
    "print(\n",
    "    '{}_{}: the mean {} for the validation set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                 'r2', np.mean(\n",
    "            stat_res[stat_res['set'] == 'va']['r2']), np.std(\n",
    "            stat_res[stat_res['set'] == 'va']['r2'])))\n",
    "print('{}_{}: the mean {} for the test set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                             'r2', np.mean(\n",
    "        stat_res[stat_res['set'] == 'te']['r2']), np.std(\n",
    "        stat_res[stat_res['set'] == 'te']['r2'])))\n",
    "\n",
    "end = time.time()  # get the end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc auc_roc recall precision f1 kappa mcc\n",
    "rmse_str = 'rmse of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['rmse']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['rmse']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['rmse']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['rmse']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['rmse']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['rmse']),\n",
    ")\n",
    "r2_str = 'r2 of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['r2']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['r2']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['r2']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['r2']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['r2']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['r2']),\n",
    ")\n",
    "mae_str = 'mae of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['mae']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['mae']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['mae']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['mae']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['mae']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['mae']),\n",
    ")\n",
    "print('the elapsed time is:', (end - start)/3600, 'H')\n",
    "print(rmse_str)\n",
    "print(r2_str)\n",
    "print(mae_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "dict1 = {\n",
    "         \"Model: \"+modelName+\" \":['rmse ','r2','mae'],\n",
    "         \"Train\":[\n",
    "                  format(np.mean(stat_res[stat_res['set'] == 'tr']['rmse']), '.3f'),\n",
    "                  format(np.mean(stat_res[stat_res['set'] == 'tr']['r2']), '.3f'),\n",
    "                  format(np.mean(stat_res[stat_res['set'] == 'tr']['mae']), '.3f')\n",
    "                 ],\n",
    "         \"Tr_STD\":[\n",
    "                   format(np.std(stat_res[stat_res['set'] == 'tr']['rmse']), '.3f'),\n",
    "                   format(np.std(stat_res[stat_res['set'] == 'tr']['r2']), '.3f'),\n",
    "                   format(np.std(stat_res[stat_res['set'] == 'tr']['mae']), '.3f')\n",
    "                  ],\n",
    "         \"Validation\":[\n",
    "                       format(np.mean(stat_res[stat_res['set'] == 'va']['rmse']), '.3f'),\n",
    "                       format(np.mean(stat_res[stat_res['set'] == 'va']['r2']), '.3f'),\n",
    "                       format(np.mean(stat_res[stat_res['set'] == 'va']['mae']), '.3f')\n",
    "                    ],\n",
    "         \"Va_STD\":[\n",
    "                   format(np.std(stat_res[stat_res['set'] == 'va']['rmse']), '.3f'),\n",
    "                   format(np.std(stat_res[stat_res['set'] == 'va']['r2']), '.3f'),\n",
    "                   format(np.std(stat_res[stat_res['set'] == 'va']['mae']), '.3f')\n",
    "                  ],\n",
    "         \"Test\":[\n",
    "                 format(np.mean(stat_res[stat_res['set'] == 'te']['rmse']), '.3f'),\n",
    "                 format(np.mean(stat_res[stat_res['set'] == 'te']['r2']), '.3f'),\n",
    "                 format(np.mean(stat_res[stat_res['set'] == 'te']['mae']), '.3f')\n",
    "                ],\n",
    "          \"Te_STD\":[\n",
    "                    format(np.std(stat_res[stat_res['set'] == 'te']['rmse']), '.3f'),\n",
    "                    format(np.std(stat_res[stat_res['set'] == 'te']['r2']), '.3f'),\n",
    "                    format(np.std(stat_res[stat_res['set'] == 'te']['mae']), '.3f')\n",
    "                   ]\n",
    "        }\n",
    "dict1 = collections.OrderedDict(dict1)\n",
    "df = pd.DataFrame(dict1,index = None)\n",
    "df.to_csv('output/'+dataset_label+'_output_'+modelName+'.csv',index = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret ",
   "language": "python",
   "name": "pycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
